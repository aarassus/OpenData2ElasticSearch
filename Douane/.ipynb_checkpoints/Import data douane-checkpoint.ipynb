{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data Douane To ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des Bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import elasticsearch\n",
    "import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch_dsl\n",
    "from datetime import datetime\n",
    "from elasticsearch_dsl import Document, Date, Nested, Boolean, analyzer, InnerDoc, Completion, Keyword, Text, Integer, Keyword, Text\n",
    "from elasticsearch_dsl.connections import connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la variable my_dir (à modifier par  l'utilisateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = r'C:/Users/aaras/Desktop/Data_Douane'\n",
    "os.chdir(my_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organisation du dossier ' Data_Douane':\n",
    "* Data_Douane\n",
    "    * National-2010-export\n",
    "      *  Libelle_NC8_2010.txt\n",
    "      *  Libelle_CPF6.txt\n",
    "      *  Libelle_A129.txt\n",
    "      *  National_2010_Export.txt\n",
    "      *  Libelle_PAYS.txt\n",
    "    * National-2010-import\n",
    "      *  Libelle_NC8_2010.txt\n",
    "      *  Libelle_CPF6.txt\n",
    "      *  Libelle_A129.txt\n",
    "      *  National_2010_Import.txt\n",
    "      *  Libelle_PAYS.txt\n",
    "    * [...]\n",
    "    * National-2019-export\n",
    "      *  Libelle_NC8_2010.txt\n",
    "      *  Libelle_CPF6.txt\n",
    "      *  Libelle_A129.txt\n",
    "      *  National_2010_Export.txt\n",
    "      *  Libelle_PAYS.txt\n",
    "    * National-2019-import\n",
    "      *  Libelle_NC8_2019.txt\n",
    "      *  Libelle_CPF6.txt\n",
    "      *  Libelle_A129.txt\n",
    "      *  National_2019_Import.txt\n",
    "      *  Libelle_PAYS.txt\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du DataFrame df.import_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explication des champs\n",
    "* Flux : le flux correspond au mouvement de la marchandise. Ce champ est valorisé à I pour\n",
    "Importation et à E pour Exportation\n",
    "* Mois : c'est le mois durant lequel a eu lieu le mouvement de marchandise.\n",
    "* Année: c'est l'année durant laquelle a eu lieu le mouvement de marchandise.\n",
    "* Code CPF6 : C'est le niveau fin de la nomenclature Classification de produits française (CPF).\n",
    "La CPF est la nomenclature statistique, nationale et centrale de produits. C'est une nomenclature de\n",
    "produit et de service. Elle permet aux données du commerce extérieur d'être intégrées avec d'autres\n",
    "statistiques économiques telles que la production industrielle ou la consommation dans des analyses\n",
    "économiques tant globales que régionales.\n",
    "* Code A129 : La nomenclature A129 correspond à une nomenclature de regroupement des niveaux\n",
    "de la CPF pour répondre aux besoins de la production de données de synthèse pour l'analyse\n",
    "économique et la diffusion.\n",
    "* Code NC8 : C'est le code de la nomenclature combinée à 8 chiffres (NC8), utilisée pour les\n",
    "obligations déclaratives des opérateurs auprès de la douane, permet une connaissance détaillée du\n",
    "commerce extérieur de la France : elle compte en effet un peu moins de 10 000 rubriques.\n",
    "* Code Pays : C'est un code à deux caractères alphabétiques attribué à chaque pays par la\n",
    "Commission des communautés européennes.\n",
    "     * À l'importation, les marchandises sont relevées au compte du pays d'origine.\n",
    "     * À l'exportation, les envois sont imputés au compte de la destination finale déclarée.\n",
    "* Valeur : La valeur des échanges est exprimée en euros.\n",
    "* Masse : Les masses sont exprimées en kilogrammes.\n",
    "* USUP : Unité supplémentaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remarques diverses sur les fichiers utilisés :\n",
    "* Vérifier que les fichier .txt sont bien encodés en utf-8. Si ce n'est pas le cas vous pouvez ouvrir le fichier dans notepad++ pour le convertir.\n",
    "* Les headers des fichiers 'Libelle_NC8_xxx.txt' ont été supprimés à la main car il n'apparaissaient pas sur tous les fichiers\n",
    "* Le code pays de la Namibie étant 'NA', ce code est par défaut détecté par pd.read_csv() comme un NaN. Il faut ajouter une liste de na_values et mettre keep_defaut_na = false la fonction pd.read_csv()\n",
    "* Ajout de 3 lignes manquantes dans le fichier Libelle_NC8_2018.txt\n",
    "    *  99500000;Marchandises de faible valeurs dans les échanges intra-communautaires;0;;1993;2018;;\n",
    "    *  99988000;Composants d'ensembles industriels non classés ailleurs;0;;1993;2018;;\n",
    "    *  99992000;Colis postaux non classés ailleurs;0;;1993;2018;;\n",
    "* Ajout de 3 lignes manquantes dans le fichier Libelle_NC8_2019.txt\n",
    "    *  99050000;Biens personnels appartenant à des personnes physiques qui transfèrent leur résidence normale;0;;2011;2019\n",
    "    *  99190000;Autres biens appartenant à des personnes physiques qui transfèrent leur résidence normale;0;;2011;2019\n",
    "    *  99500000;Marchandises de faible valeurs dans les échanges intra-communautaires;0;;1993;2019\n",
    "    *  99992000;Colis postaux non classés ailleurs;0;;1993;2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_df_import_export(liste_annee):\n",
    "    \n",
    "    '''création d'/un dataframe contenant les données d'/import/export des douanes pour la liste d'années spécifiées en entrée'''\n",
    "    \n",
    "    df_columns = ['Code_Flux', 'Libelle_Flux', 'Mois', 'Annee', 'Date_DateTime', 'Code_CPF6', 'Libelle_CPF6', 'Code_A129', 'Libelle_A129', 'Code_NC8', 'Libelle_NC8', 'Code_Pays', 'Libelle_Pays', 'Valeur', 'Masse', 'USUP']\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "    \n",
    "    for annee in liste_annee:\n",
    "        df_import_export = creation_df_import_export_annee(annee)\n",
    "        df = pd.concat([df,df_import_export])\n",
    "        print('Année {} ajoutée, {} import/export ajoutés depuis {}'.format(annee, df.shape[0], liste_annee[0]))\n",
    "\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_df_import_export_annee(annee):\n",
    "    \n",
    "    '''Création d'un dataframe pour l'année courante de la forme ['Code_Flux', 'Libelle_Flux', 'Mois', 'Annee', 'Date_DateTime', 'Code_CPF6', 'Libelle_CPF6', 'Code_A129', 'Libelle_A129', 'Code_NC8', 'Libelle_NC8', 'Code_Pays', 'Libelle_Pays', 'Valeur', 'Masse', 'USUP']'''\n",
    "    \n",
    "    df_import, df_export, df_nc8, df_pays, df_cpf6, df_a129 = csv_to_df(annee) #on charge les 6 fichiers (import, export, et table de conversion nc8, a129, cpf6, pays)\n",
    "    df = pd.concat([df_import,df_export]) # on fusionne les imports et les exports\n",
    "    df = pd.merge(df, df_nc8, how='left') # on ajoute le libelle nc8\n",
    "    df = pd.merge(df, df_nc8, how='left') # on ajoute le libelle nc8    \n",
    "    df = pd.merge(df, df_a129, how='left') # on ajoute le libelle a129\n",
    "    df = pd.merge(df, df_cpf6, how='left') # on ajoute le libelle cpf6\n",
    "    df = pd.merge(df, df_pays, how='left') # on ajoute le libelle pays\n",
    "    df = df_add_date_datetime(df) # on ajopute une colonne date au format datetime\n",
    "    df = df_add_libelle_flux(df) # on ajoute import/export en toute lettre\n",
    "    new_columns_order = ['Code_Flux', 'Libelle_Flux', 'Mois', 'Annee', 'Date_DateTime', 'Code_CPF6', 'Libelle_CPF6', 'Code_A129', 'Libelle_A129', 'Code_NC8', 'Libelle_NC8', 'Code_Pays', 'Libelle_Pays', 'Valeur', 'Masse', 'USUP']\n",
    "    df = df.reindex(columns = new_columns_order)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(annee):\n",
    "    \n",
    "    '''création d'un dataframe contenant les données d'import/export des douanes pour l'année spécifiée en entrée'''\n",
    "    \n",
    "    import_dir = os.path.join(my_dir,'National-'+str(annee)+'-import')\n",
    "    export_dir = os.path.join(my_dir,'National-'+str(annee)+'-export')\n",
    "    na_values_liste = ['#N/A', '#N/A', 'N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN',' N/A',' NULL', 'NaN', 'n/a','nan', 'null']\n",
    "    columns_name = ['Code_Flux', 'Mois', 'Annee', 'Code_CPF6','Code_A129','Code_NC8','Code_Pays','Valeur', 'Masse', 'USUP']\n",
    "    dtype_dico = {'Code_Flux': object , 'Mois': int , 'Annee': int, 'Code_CPF6': object, 'Code_A129': object, 'Code_NC8':object,'Code_Pays':object, 'Valeur':int, 'Masse':int, 'USUP':int}\n",
    "    os.chdir(import_dir)\n",
    "    df_import = pd.read_csv('National_'+str(annee)+'_Import.txt', sep=\";\", header=None, encoding = 'utf-8', names=columns_name, dtype=dtype_dico, keep_default_na=False, na_values = na_values_liste)\n",
    "    os.chdir(export_dir)\n",
    "    df_export = pd.read_csv('National_'+str(annee)+'_Export.txt', sep=\";\", header=None, encoding = 'utf-8', names=columns_name, dtype=dtype_dico, keep_default_na=False, na_values = na_values_liste)\n",
    "    df_nc8 = pd.read_csv('Libelle_NC8_'+str(annee)+'.txt', sep=\";\", header=None, names = ['Code_NC8','Libelle_NC8'], encoding = 'utf-8',  usecols = [0,1], dtype={'Code_NC8':object,'Libelle_NC8':object} )\n",
    "    df_a129 = pd.read_csv('Libelle_A129.txt', sep=\";\", header=None, names = ['Code_A129','Libelle_A129','c','d'], usecols = ['Code_A129','Libelle_A129'], dtype={'Code_A129':object,'Libelle_A129':object})\n",
    "    df_cpf6 = pd.read_csv('Libelle_CPF6.txt', sep=\";\", header=None, names = ['Code_CPF6', 'Libelle_CPF6','c','d'], usecols = ['Code_CPF6', 'Libelle_CPF6'],dtype={'Code_CPF6':object,'Libelle_CPF6':object})\n",
    "    df_pays = pd.read_csv('Libelle_PAYS.txt', sep=\";\", header=None, names = ['Code_Pays', 'Libelle_Pays', 'c','d'],usecols=['Code_Pays', 'Libelle_Pays'], dtype={'Code_Pays':object,'Libelle_Pays':object},keep_default_na=False, na_values = na_values_liste)\n",
    "    return df_import, df_export, df_nc8, df_pays, df_cpf6, df_a129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_date_datetime(df):\n",
    "    \n",
    "    '''A partir des colonnes Annee et Mois du dataframe, création d'une nouvelle colonne Date au format datetime'''\n",
    "    \n",
    "    df = df.assign(Date_DateTime = pd.to_datetime({'year':df.Annee,'month':df.Mois,'day':1}))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_libelle_flux(df):\n",
    "    \n",
    "    '''Création d'une nouvelle colonne spécifiant en toute lettre s'il s'agit d'un import ou d'un export'''\n",
    "    \n",
    "    df_flux = pd.DataFrame([['I','Import'],['E','Export']],columns=['Code_Flux', 'Libelle_Flux'])\n",
    "    df = pd.merge(df, df_flux,how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Année 2010 ajoutée, 3728478 import/export ajoutés depuis 2010\n",
      "Année 2011 ajoutée, 7503145 import/export ajoutés depuis 2010\n",
      "Année 2012 ajoutée, 11392481 import/export ajoutés depuis 2010\n"
     ]
    }
   ],
   "source": [
    "liste_annee = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "df = creation_df_import_export(liste_annee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(my_dir)\n",
    "df.to_csv('National_2010_2019_Import_Export.csv', index=False) #créé un fichier de 15 Go donc peut être pas une bonne idée :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.head(10000)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export vers ElasticSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_DateTime'] = df['Date_DateTime'].astype(str)\n",
    "df_export\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX=\"douane_2\"\n",
    "TYPE= \"record\"\n",
    "\n",
    "def rec_to_actions(df):\n",
    "    import json\n",
    "    for record in df.to_dict(orient=\"records\"):\n",
    "        yield ('{ \"index\" : { \"_index\" : \"%s\", \"_type\" : \"%s\" }}'% (INDEX, TYPE))\n",
    "        yield (json.dumps(record))\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "e = Elasticsearch() # no args, connect to localhost:9200\n",
    "if not e.indices.exists(INDEX):\n",
    "    raise RuntimeError('index does not exists, use `curl -X PUT \"localhost:9200/%s\"` and try again'%INDEX)\n",
    "\n",
    "r = e.bulk(rec_to_actions(df)) # return a dict\n",
    "\n",
    "print(not r[\"errors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connections.create_connection(hosts=['localhost'])\n",
    "\n",
    "class Import_Export_Douane(Document):\n",
    "    flux = Keyword()\n",
    "    mois = Integer() \n",
    "    annee = Integer()\n",
    "    code_CPF6 = Keyword()\n",
    "    libelle_CPF6 = Text()\n",
    "    code_A129 = Keyword()\n",
    "    libelle_A129 = Text()\n",
    "    code_NC8 = Keyword()\n",
    "    libelle_NC8 = Text()\n",
    "    code_pays = Keyword()\n",
    "    libelle_pays = Keyword()\n",
    "    valeur = Integer()\n",
    "    masse = Integer()\n",
    "    usup = Integer()\n",
    "    \n",
    "    class Index:\n",
    "        name = 'import_export_douane'\n",
    "\n",
    "    def save(self, ** kwargs):\n",
    "        return super(Import_Export_Douane, self).save(** kwargs)\n",
    "\n",
    "    def is_published(self):\n",
    "        return datetime.now() >= self.published_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df(df):\n",
    "    lis = []\n",
    "    for i in range (df.shape[0]):\n",
    "        info_export = df.loc[i].tolist() #['Flux', 'Mois', 'Annee', 'Code_CPF6','Code_A129','Code_NC8','Code_Pays','Valeur', 'Masse', 'USUP'] \n",
    "         # create and save and article\n",
    "        doc = Import_Export_Douane(meta={'id': i}, tags=['test'])\n",
    "        doc.flux = info_export[0]\n",
    "        doc.mois =  info_export[1]\n",
    "        doc.annee = info_export[2]\n",
    "        doc.code_CPF6 = info_export[3]\n",
    "        doc.libelle_CPF6 = info_export[4]\n",
    "        doc.code_A129 = info_export[5]\n",
    "        doc.libelle_A129 = info_export[6]\n",
    "        doc.code_NC8 = info_export[7]\n",
    "        doc.libelle_NC8 = info_export[8]\n",
    "        doc.code_pays = info_export[9]\n",
    "        doc.libelle_pays = info_export[10]\n",
    "        doc.valeur = info_export[11]\n",
    "        doc.masse = info_export[12]\n",
    "        doc.usup = info_export[13]\n",
    "        doc.published_from = datetime.now()\n",
    "        doc.save(doc_type=\"test\")\n",
    "        print('Export n°{} importé'.format(i))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.create_connection(hosts=['localhost'])\n",
    "import_df(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
