{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data Douane To ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des Bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch_dsl\n",
    "from datetime import datetime\n",
    "from elasticsearch_dsl import Document, Date, Nested, Boolean, analyzer, InnerDoc, Completion, Keyword, Text, Integer, Keyword, Text\n",
    "from elasticsearch_dsl.connections import connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la variable my_dir (à modifier par  l'utilisateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = r'C:/Users/aaras/Desktop/Data_Douane'\n",
    "os.chdir(my_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du DataFrame df.import_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_nc8(df_import_export, df_nc8):\n",
    "    df_import_export = pd.merge(df_import_export, df_nc8,how='left')\n",
    "    return df_import_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rq: Vérifier que les fichier .txt sont bien encodés en utf-8. Si ce n'est pas le cas vous pouvez ouvrir le fichier dans notepad++ pour le convertir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_annee = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\n",
    "def creation_df_import_export_nc8(liste_annee):\n",
    "    data_dir = os.path.join(my_dir,'data')\n",
    "    os.chdir(data_dir)\n",
    "    df_import_export = pd.DataFrame(columns=['Flux', 'Mois', 'Annee', 'Code_CPF6','Code_A129','Code_NC8','Code_Pays','Valeur', 'Masse', 'USUP'])\n",
    "    for annee in liste_annee:\n",
    "        df_import = pd.read_csv('National_'+str(annee)+'_Import.txt',sep=\";\",header=None,names=['Flux', 'Mois', 'Annee', 'Code_CPF6','Code_A129','Code_NC8','Code_Pays','Valeur', 'Masse', 'USUP'],dtype={'Flux': object , 'Mois': int , 'Annee': int, 'Code_CPF6': object, 'Code_A129': object, 'Code_NC8':object,'Code_Pays':object, 'Valeur':int, 'Masse':int, 'USUP':int},keep_default_na=False, na_values = ['#N/A', '#N/A', 'N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN',' N/A',' NULL', 'NaN', 'n/a','nan', 'null'])\n",
    "        df_export = pd.read_csv('National_'+str(annee)+'_Export.txt',sep=\";\",header=None,names=['Flux', 'Mois', 'Annee', 'Code_CPF6','Code_A129','Code_NC8','Code_Pays','Valeur', 'Masse', 'USUP'],dtype={'Flux': object , 'Mois': int , 'Annee': int, 'Code_CPF6': object, 'Code_A129': object, 'Code_NC8':object,'Code_Pays':object, 'Valeur':int, 'Masse':int, 'USUP':int},keep_default_na=False, na_values = ['#N/A', '#N/A', 'N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN',' N/A',' NULL', 'NaN', 'n/a','nan', 'null'])\n",
    "        df_nc8 = pd.read_csv('Libelle_NC8_'+str(annee)+'.txt', sep=\";\", header=None, names = ['Code_NC8','Libelle_NC8'], encoding = 'utf-8',  usecols = [0,1], dtype={'Code_NC8':object,'Libelle_NC8':object} )\n",
    "        df_import_export = pd.concat([df_import,df_export])\n",
    "        df_import_export_nc8 = join_nc8(df_import_export, df_nc8)\n",
    "        print(str(annee)+' ajoutée')\n",
    "    return df_import_export_nc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 ajoutée\n",
      "2011 ajoutée\n",
      "2012 ajoutée\n",
      "2013 ajoutée\n",
      "2014 ajoutée\n",
      "2015 ajoutée\n",
      "2016 ajoutée\n",
      "2017 ajoutée\n",
      "2018 ajoutée\n",
      "2019 ajoutée\n"
     ]
    }
   ],
   "source": [
    "df = creation_df_import_export_nc8(liste_annee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rq: Les headers des fichiers 'Libelle_NC8_xxx.txt' ont été supprimés à la main car il n'apparaissaient pas sur tous les fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création dataFrame df.a129, df.cpf6 et df.pays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rq: Le code pays de la Namibie étant 'NA', ce code est par défaut détecté par pd.read_csv() comme un NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data_dir = os.path.join(my_dir,'additional_data')\n",
    "os.chdir(additional_data_dir)\n",
    "df_a129 = pd.read_csv('Libelle_A129.txt', sep=\";\", header=None, names = ['Code_A129','Libelle_A129','c','d'], usecols = ['Code_A129','Libelle_A129'], dtype={'Code_A129':object,'Libelle_A129':object})\n",
    "print('df_a129 créé')\n",
    "df_cpf6 = pd.read_csv('Libelle_CPF6.txt', sep=\";\", header=None, names = ['Code_CPF6', 'Libelle_CPF6','c','d'], usecols = ['Code_CPF6', 'Libelle_CPF6'],dtype={'Code_CPF6':object,'Libelle_CPF6':object})\n",
    "print('df_cpf6 créé')\n",
    "df_pays = pd.read_csv('Libelle_PAYS.txt', sep=\";\", header=None, names = ['Code_Pays', 'Libelle_Pays', 'c','d'],usecols=['Code_Pays', 'Libelle_Pays'], dtype={'Code_Pays':object,'Libelle_Pays':object},keep_default_na=False, na_values = ['#N/A', '#N/A', 'N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN',' N/A',' NULL', 'NaN', 'n/a','nan', 'null'])\n",
    "print('df_pays créé')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jointure sur df_import_export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_a129, how='left')\n",
    "print('Libellés A129 ajoutés')\n",
    "df = pd.merge(df, df_cpf6,how='left')\n",
    "print('Libellés CPF6 ajoutés')\n",
    "df = pd.merge(df, df_pays,how='left')\n",
    "print('Libellés Pays ajoutés')\n",
    "new_columns_order = ['Flux', 'Mois', 'Annee', 'Code_CPF6', 'Libelle_CPF6', 'Code_A129','Libelle_A129', 'Code_NC8', 'Libelle_NC8','Code_Pays','Libelle_Pays', 'Valeur', 'Masse', 'USUP']\n",
    "df = df.reindex(columns = new_columns_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explication des champs\n",
    "* Flux : le flux correspond au mouvement de la marchandise. Ce champ est valorisé à I pour\n",
    "Importation et à E pour Exportation\n",
    "* Mois : c'est le mois durant lequel a eu lieu le mouvement de marchandise.\n",
    "* Année: c'est l'année durant laquelle a eu lieu le mouvement de marchandise.\n",
    "* Code CPF6 : C'est le niveau fin de la nomenclature Classification de produits française (CPF).\n",
    "La CPF est la nomenclature statistique, nationale et centrale de produits. C'est une nomenclature de\n",
    "produit et de service. Elle permet aux données du commerce extérieur d'être intégrées avec d'autres\n",
    "statistiques économiques telles que la production industrielle ou la consommation dans des analyses\n",
    "économiques tant globales que régionales.\n",
    "* Code A129 : La nomenclature A129 correspond à une nomenclature de regroupement des niveaux\n",
    "de la CPF pour répondre aux besoins de la production de données de synthèse pour l'analyse\n",
    "économique et la diffusion.\n",
    "* Code NC8 : C'est le code de la nomenclature combinée à 8 chiffres (NC8), utilisée pour les\n",
    "obligations déclaratives des opérateurs auprès de la douane, permet une connaissance détaillée du\n",
    "commerce extérieur de la France : elle compte en effet un peu moins de 10 000 rubriques.\n",
    "* Code Pays : C'est un code à deux caractères alphabétiques attribué à chaque pays par la\n",
    "Commission des communautés européennes.\n",
    "     * À l'importation, les marchandises sont relevées au compte du pays d'origine.\n",
    "     * À l'exportation, les envois sont imputés au compte de la destination finale déclarée.\n",
    "* Valeur : La valeur des échanges est exprimée en euros.\n",
    "* Masse : Les masses sont exprimées en kilogrammes.\n",
    "* USUP : Unité supplémentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connections.create_connection(hosts=['localhost'])\n",
    "\n",
    "class Import_Export_Douane(Document):\n",
    "    flux = Keyword()\n",
    "    mois = Integer() \n",
    "    annee = Integer()\n",
    "    code_CPF6 = Keyword()\n",
    "    libelle_CPF6 = Text()\n",
    "    code_A129 = Keyword()\n",
    "    libelle_A129 = Text()\n",
    "    code_NC8 = Keyword()\n",
    "    libelle_NC8 = Text()\n",
    "    code_pays = Keyword()\n",
    "    libelle_pays = Keyword()\n",
    "    valeur = Integer()\n",
    "    masse = Integer()\n",
    "    usup = Integer()\n",
    "    \n",
    "    class Index:\n",
    "        name = 'import_export_douane'\n",
    "\n",
    "    def save(self, ** kwargs):\n",
    "        return super(Import_Export_Douane, self).save(** kwargs)\n",
    "\n",
    "    def is_published(self):\n",
    "        return datetime.now() >= self.published_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df(df):\n",
    "    lis = []\n",
    "    for i in range (df.shape[0]):\n",
    "        info_export = df.loc[i].tolist() #['Flux', 'Mois', 'Annee', 'Code_CPF6','Code_A129','Code_NC8','Code_Pays','Valeur', 'Masse', 'USUP'] \n",
    "         # create and save and article\n",
    "        doc = Import_Export_Douane(meta={'id': i}, tags=['test'])\n",
    "        doc.flux = info_export[0]\n",
    "        doc.mois =  info_export[1]\n",
    "        doc.annee = info_export[2]\n",
    "        doc.code_CPF6 = info_export[3]\n",
    "        doc.libelle_CPF6 = info_export[4]\n",
    "        doc.code_A129 = info_export[5]\n",
    "        doc.libelle_A129 = info_export[6]\n",
    "        doc.code_NC8 = info_export[7]\n",
    "        doc.libelle_NC8 = info_export[8]\n",
    "        doc.code_pays = info_export[9]\n",
    "        doc.libelle_pays = info_export[10]\n",
    "        doc.valeur = info_export[11]\n",
    "        doc.masse = info_export[12]\n",
    "        doc.usup = info_export[13]\n",
    "        doc.published_from = datetime.now()\n",
    "        doc.save(doc_type=\"test\")\n",
    "        print('Export n°{} importé'.format(i))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.create_connection(hosts=['localhost'])\n",
    "import_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX=\"douane\"\n",
    "TYPE= \"record\"\n",
    "\n",
    "def rec_to_actions(df):\n",
    "    for record in df.to_dict(orient=\"records\"):\n",
    "        yield ('{ \"index\" : { \"_index\" : \"%s\", \"_type\" : \"%s\" }}'% (INDEX, TYPE))\n",
    "        yield (json.dumps(record, default=int))\n",
    "\n",
    "e = Elasticsearch() # no args, connect to localhost:9200\n",
    "if not e.indices.exists(INDEX):\n",
    "    raise RuntimeError('index does not exists, use `curl -X PUT \"localhost:9200/%s\"` and try again'%INDEX)\n",
    "\n",
    "r = e.bulk(rec_to_actions(df)) # return a dict\n",
    "\n",
    "print(not r[\"errors\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))\n",
    "\n",
    "INDEX=\"dataframe\"\n",
    "TYPE= \"record\"\n",
    "\n",
    "def rec_to_actions(df):\n",
    "    import json\n",
    "    for record in df.to_dict(orient=\"records\"):\n",
    "        yield ('{ \"index\" : { \"_index\" : \"%s\", \"_type\" : \"%s\" }}'% (INDEX, TYPE))\n",
    "        yield (json.dumps(record, default=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Elasticsearch()\n",
    "r = e.bulk(rec_to_actions(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
